{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T03:48:13.181775Z",
     "iopub.status.busy": "2022-06-26T03:48:13.180864Z",
     "iopub.status.idle": "2022-06-26T03:48:13.423813Z",
     "shell.execute_reply": "2022-06-26T03:48:13.423106Z",
     "shell.execute_reply.started": "2022-06-26T03:48:13.181726Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /home/aistudio/data/data154549/train_data_01/train_data_01/\n",
    "import paddle\n",
    "print(paddle.device.get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n",
    "1.将提供的10个数据集合并成一个数据集\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "inpath = r\"D:\\BaiduNetdiskDownload\\train_data_01\\train_data_01\\blur_image\"\n",
    "tarpath = r\"D:\\BaiduNetdiskDownload\\train_data_01\\train_data_01\\gt_image\" \n",
    "\n",
    "for i in range(2,10):\n",
    "    print(os.path.join(r\"D:\\BaiduNetdiskDownload\\train_data_0\"+str(i),\"train_data_0\"+str(i)+r\"\\blur_image\\*.png\"))\n",
    "    input1 = glob.glob(os.path.join(r\"D:\\BaiduNetdiskDownload\\train_data_0\"+str(i),\"train_data_0\"+str(i)+r\"\\blur_image\\*.png\"))\n",
    "    target = glob.glob(os.path.join(r\"D:\\BaiduNetdiskDownload\\train_data_0\"+str(i),\"train_data_0\"+str(i)+r\"\\gt_image\\*.png\"))    \n",
    "    print(input1)\n",
    "    for j,k in zip(input1,target):\n",
    "        shutil.move(j,os.path.join(inpath,os.path.basename(j)))\n",
    "        shutil.move(k,os.path.join(tarpath,os.path.basename(k)))\n",
    "               \n",
    "for i in [10]:\n",
    "    print(os.path.join(r\"D:\\BaiduNetdiskDownload\\train_data_0\"+str(i),\"train_data_0\"+str(i)+r\"\\blur_image\\*.png\"))\n",
    "    input1 = glob.glob(os.path.join(r\"D:\\BaiduNetdiskDownload\\train_data_\"+str(i),\"train_data_\"+str(i)+r\"\\blur_image\\*.png\"))\n",
    "    target = glob.glob(os.path.join(r\"D:\\BaiduNetdiskDownload\\train_data_\"+str(i),\"train_data_\"+str(i)+r\"\\gt_image\\*.png\"))    \n",
    "    print(input1)\n",
    "    for j,k in zip(input1,target):\n",
    "        shutil.move(j,os.path.join(inpath,os.path.basename(j)))\n",
    "        shutil.move(k,os.path.join(tarpath,os.path.basename(k)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**1.构造数据读取器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T15:22:46.489503Z",
     "iopub.status.busy": "2022-09-06T15:22:46.489033Z",
     "iopub.status.idle": "2022-09-06T15:22:55.094981Z",
     "shell.execute_reply": "2022-09-06T15:22:55.093760Z",
     "shell.execute_reply.started": "2022-09-06T15:22:46.489472Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 23:22:49.488724  2870 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W0906 23:22:49.492609  2870 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [16, 3, 256, 256] [16, 3, 256, 256]\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "class MyDateset(paddle.io.Dataset):\n",
    "    def __init__(self, mode = 'train', watermark_dir = 'data/data154549/train_data_01/train_data_01/blur_image/', bg_dir = 'data/data154549/train_data_01/train_data_01/gt_image/'):\n",
    "        super(MyDateset, self).__init__()\n",
    "\n",
    "        self.mode = mode \n",
    "        self.watermark_dir = watermark_dir\n",
    "        self.bg_dir = bg_dir\n",
    "\n",
    "        self.train_list = os.listdir(self.watermark_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.train_list[index]\n",
    "        #bg_item = item[:14]+'.jpg'\n",
    "\n",
    "        img = cv2.imread(self.watermark_dir+item)\n",
    "        label = cv2.imread(self.bg_dir+item)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n",
    "        #img = paddle.vision.transforms.resize(img, (512,512), interpolation='bilinear')\n",
    "        #label = paddle.vision.transforms.resize(label, (512,512), interpolation='bilinear')\n",
    "        # 随机选择512的patch\n",
    "        ps = 256\n",
    "        hh, ww = label.shape[0], label.shape[1]\n",
    "        rr     = random.randint(0, hh-ps)\n",
    "        cc     = random.randint(0, ww-ps)\n",
    "        img = img[rr:rr+ps, cc:cc+ps,:]\n",
    "        label = label[rr:rr+ps, cc:cc+ps,:]\n",
    "\n",
    "        img = img.transpose((2,0,1))\n",
    "        label = label.transpose((2,0,1))\n",
    "        \n",
    "        img = img/255\n",
    "        label = label/255\n",
    "\n",
    "        img = paddle.to_tensor(img).astype('float32')\n",
    "        label = paddle.to_tensor(label).astype('float32')\n",
    "\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "# 对dataloader进行测试\n",
    "\n",
    "train_dataset=MyDateset()\n",
    "\n",
    "train_dataloader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=False)\n",
    "\n",
    "for step, data in enumerate(train_dataloader):\n",
    "    img, label = data\n",
    "    print(step, img.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.定义网络结构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T15:23:03.534959Z",
     "iopub.status.busy": "2022-09-06T15:23:03.533928Z",
     "iopub.status.idle": "2022-09-06T15:23:05.462968Z",
     "shell.execute_reply": "2022-09-06T15:23:05.462054Z",
     "shell.execute_reply.started": "2022-09-06T15:23:03.534918Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "    Layer (type)                   Input Shape                    Output Shape         Param #    \n",
      "====================================================================================================\n",
      "      Conv2D-1                  [[1, 3, 256, 256]]             [1, 64, 256, 256]        1,728     \n",
      "    AvgPool2D-1                [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-17                 [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "       Down-1                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    DownSample-1               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-2                [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-18                 [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "       Down-2                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    DownSample-2               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-3                [[1, 96, 128, 128]]              [1, 96, 64, 64]           0       \n",
      "     Conv2D-19                  [[1, 96, 64, 64]]               [1, 144, 64, 64]       13,824     \n",
      "       Down-3                  [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "    DownSample-3               [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "      Conv2D-2                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       36,864     \n",
      "    LeakyReLU-1                [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "      Conv2D-3                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       36,864     \n",
      "      Conv2D-4                 [[1, 64, 256, 256]]              [1, 1, 256, 256]         64       \n",
      "     Softmax-1                   [[1, 1, 65536]]                 [1, 1, 65536]            0       \n",
      "      Conv2D-5                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "    LeakyReLU-2                  [[1, 64, 1, 1]]                 [1, 64, 1, 1]            0       \n",
      "      Conv2D-6                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "   ContextBlock-1              [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "       RCB-1                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "      Conv2D-7                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       82,944     \n",
      "    LeakyReLU-3                [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "      Conv2D-8                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       82,944     \n",
      "      Conv2D-9                 [[1, 96, 128, 128]]              [1, 1, 128, 128]         96       \n",
      "     Softmax-2                   [[1, 1, 16384]]                 [1, 1, 16384]            0       \n",
      "     Conv2D-10                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "    LeakyReLU-4                  [[1, 96, 1, 1]]                 [1, 96, 1, 1]            0       \n",
      "     Conv2D-11                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "   ContextBlock-2              [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "       RCB-2                   [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-12                  [[1, 144, 64, 64]]              [1, 144, 64, 64]       186,624    \n",
      "    LeakyReLU-5                 [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-13                  [[1, 144, 64, 64]]              [1, 144, 64, 64]       186,624    \n",
      "     Conv2D-14                  [[1, 144, 64, 64]]               [1, 1, 64, 64]          144      \n",
      "     Softmax-3                    [[1, 1, 4096]]                  [1, 1, 4096]            0       \n",
      "     Conv2D-15                   [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "    LeakyReLU-6                  [[1, 144, 1, 1]]                [1, 144, 1, 1]           0       \n",
      "     Conv2D-16                   [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "   ContextBlock-3               [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "       RCB-3                    [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-22                  [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "     Upsample-3                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "        Up-3                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     UpSample-3                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "AdaptiveAvgPool2D-2            [[1, 96, 128, 128]]               [1, 96, 1, 1]            0       \n",
      "     Conv2D-28                   [[1, 96, 1, 1]]                 [1, 12, 1, 1]          1,152     \n",
      "    LeakyReLU-8                  [[1, 12, 1, 1]]                 [1, 12, 1, 1]            0       \n",
      "     Conv2D-29                   [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Conv2D-30                   [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Softmax-5                  [[1, 2, 96, 1, 1]]              [1, 2, 96, 1, 1]          0       \n",
      "       SKFF-2        [[[1, 96, 128, 128], [1, 96, 128, 128]]]  [1, 96, 128, 128]          0       \n",
      "     Conv2D-20                 [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "     Upsample-1                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "        Up-1                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     UpSample-1                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "AdaptiveAvgPool2D-1            [[1, 64, 256, 256]]               [1, 64, 1, 1]            0       \n",
      "     Conv2D-25                   [[1, 64, 1, 1]]                  [1, 8, 1, 1]           512      \n",
      "    LeakyReLU-7                   [[1, 8, 1, 1]]                  [1, 8, 1, 1]            0       \n",
      "     Conv2D-26                    [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Conv2D-27                    [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Softmax-4                  [[1, 2, 64, 1, 1]]              [1, 2, 64, 1, 1]          0       \n",
      "       SKFF-1        [[[1, 64, 256, 256], [1, 64, 256, 256]]]  [1, 64, 256, 256]          0       \n",
      "     Conv2D-23                  [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "     Upsample-4                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "        Up-4                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     UpSample-4                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-21                 [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "     Upsample-2                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "        Up-2                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     UpSample-2                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-24                 [[1, 64, 256, 256]]             [1, 64, 256, 256]        4,096     \n",
      "       MRB-1                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "    AvgPool2D-4                [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-46                 [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "       Down-4                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    DownSample-4               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-5                [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-47                 [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "       Down-5                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    DownSample-5               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-6                [[1, 96, 128, 128]]              [1, 96, 64, 64]           0       \n",
      "     Conv2D-48                  [[1, 96, 64, 64]]               [1, 144, 64, 64]       13,824     \n",
      "       Down-6                  [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "    DownSample-6               [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-31                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       36,864     \n",
      "    LeakyReLU-9                [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-32                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       36,864     \n",
      "     Conv2D-33                 [[1, 64, 256, 256]]              [1, 1, 256, 256]         64       \n",
      "     Softmax-6                   [[1, 1, 65536]]                 [1, 1, 65536]            0       \n",
      "     Conv2D-34                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "    LeakyReLU-10                 [[1, 64, 1, 1]]                 [1, 64, 1, 1]            0       \n",
      "     Conv2D-35                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "   ContextBlock-4              [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "       RCB-4                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-36                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       82,944     \n",
      "    LeakyReLU-11               [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-37                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       82,944     \n",
      "     Conv2D-38                 [[1, 96, 128, 128]]              [1, 1, 128, 128]         96       \n",
      "     Softmax-7                   [[1, 1, 16384]]                 [1, 1, 16384]            0       \n",
      "     Conv2D-39                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "    LeakyReLU-12                 [[1, 96, 1, 1]]                 [1, 96, 1, 1]            0       \n",
      "     Conv2D-40                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "   ContextBlock-5              [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "       RCB-5                   [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-41                  [[1, 144, 64, 64]]              [1, 144, 64, 64]       186,624    \n",
      "    LeakyReLU-13                [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-42                  [[1, 144, 64, 64]]              [1, 144, 64, 64]       186,624    \n",
      "     Conv2D-43                  [[1, 144, 64, 64]]               [1, 1, 64, 64]          144      \n",
      "     Softmax-8                    [[1, 1, 4096]]                  [1, 1, 4096]            0       \n",
      "     Conv2D-44                   [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "    LeakyReLU-14                 [[1, 144, 1, 1]]                [1, 144, 1, 1]           0       \n",
      "     Conv2D-45                   [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "   ContextBlock-6               [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "       RCB-6                    [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-51                  [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "     Upsample-7                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "        Up-7                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     UpSample-7                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "AdaptiveAvgPool2D-4            [[1, 96, 128, 128]]               [1, 96, 1, 1]            0       \n",
      "     Conv2D-57                   [[1, 96, 1, 1]]                 [1, 12, 1, 1]          1,152     \n",
      "    LeakyReLU-16                 [[1, 12, 1, 1]]                 [1, 12, 1, 1]            0       \n",
      "     Conv2D-58                   [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Conv2D-59                   [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Softmax-10                 [[1, 2, 96, 1, 1]]              [1, 2, 96, 1, 1]          0       \n",
      "       SKFF-4        [[[1, 96, 128, 128], [1, 96, 128, 128]]]  [1, 96, 128, 128]          0       \n",
      "     Conv2D-49                 [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "     Upsample-5                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "        Up-5                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     UpSample-5                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "AdaptiveAvgPool2D-3            [[1, 64, 256, 256]]               [1, 64, 1, 1]            0       \n",
      "     Conv2D-54                   [[1, 64, 1, 1]]                  [1, 8, 1, 1]           512      \n",
      "    LeakyReLU-15                  [[1, 8, 1, 1]]                  [1, 8, 1, 1]            0       \n",
      "     Conv2D-55                    [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Conv2D-56                    [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Softmax-9                  [[1, 2, 64, 1, 1]]              [1, 2, 64, 1, 1]          0       \n",
      "       SKFF-3        [[[1, 64, 256, 256], [1, 64, 256, 256]]]  [1, 64, 256, 256]          0       \n",
      "     Conv2D-52                  [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "     Upsample-8                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "        Up-8                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     UpSample-8                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-50                 [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "     Upsample-6                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "        Up-6                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     UpSample-6                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-53                 [[1, 64, 256, 256]]             [1, 64, 256, 256]        4,096     \n",
      "       MRB-2                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-60                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       36,864     \n",
      "       RRG-1                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "    AvgPool2D-7                [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-76                 [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "       Down-7                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    DownSample-7               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-8                [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-77                 [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "       Down-8                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    DownSample-8               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-9                [[1, 96, 128, 128]]              [1, 96, 64, 64]           0       \n",
      "     Conv2D-78                  [[1, 96, 64, 64]]               [1, 144, 64, 64]       13,824     \n",
      "       Down-9                  [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "    DownSample-9               [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-61                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       18,432     \n",
      "    LeakyReLU-17               [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-62                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       18,432     \n",
      "     Conv2D-63                 [[1, 64, 256, 256]]              [1, 1, 256, 256]         64       \n",
      "     Softmax-11                  [[1, 1, 65536]]                 [1, 1, 65536]            0       \n",
      "     Conv2D-64                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "    LeakyReLU-18                 [[1, 64, 1, 1]]                 [1, 64, 1, 1]            0       \n",
      "     Conv2D-65                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "   ContextBlock-7              [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "       RCB-7                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-66                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       41,472     \n",
      "    LeakyReLU-19               [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-67                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       41,472     \n",
      "     Conv2D-68                 [[1, 96, 128, 128]]              [1, 1, 128, 128]         96       \n",
      "     Softmax-12                  [[1, 1, 16384]]                 [1, 1, 16384]            0       \n",
      "     Conv2D-69                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "    LeakyReLU-20                 [[1, 96, 1, 1]]                 [1, 96, 1, 1]            0       \n",
      "     Conv2D-70                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "   ContextBlock-8              [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "       RCB-8                   [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-71                  [[1, 144, 64, 64]]              [1, 144, 64, 64]       93,312     \n",
      "    LeakyReLU-21                [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-72                  [[1, 144, 64, 64]]              [1, 144, 64, 64]       93,312     \n",
      "     Conv2D-73                  [[1, 144, 64, 64]]               [1, 1, 64, 64]          144      \n",
      "     Softmax-13                   [[1, 1, 4096]]                  [1, 1, 4096]            0       \n",
      "     Conv2D-74                   [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "    LeakyReLU-22                 [[1, 144, 1, 1]]                [1, 144, 1, 1]           0       \n",
      "     Conv2D-75                   [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "   ContextBlock-9               [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "       RCB-9                    [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-81                  [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-11                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-11                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-11                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "AdaptiveAvgPool2D-6            [[1, 96, 128, 128]]               [1, 96, 1, 1]            0       \n",
      "     Conv2D-87                   [[1, 96, 1, 1]]                 [1, 12, 1, 1]          1,152     \n",
      "    LeakyReLU-24                 [[1, 12, 1, 1]]                 [1, 12, 1, 1]            0       \n",
      "     Conv2D-88                   [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Conv2D-89                   [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Softmax-15                 [[1, 2, 96, 1, 1]]              [1, 2, 96, 1, 1]          0       \n",
      "       SKFF-6        [[[1, 96, 128, 128], [1, 96, 128, 128]]]  [1, 96, 128, 128]          0       \n",
      "     Conv2D-79                 [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "     Upsample-9                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "        Up-9                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     UpSample-9                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "AdaptiveAvgPool2D-5            [[1, 64, 256, 256]]               [1, 64, 1, 1]            0       \n",
      "     Conv2D-84                   [[1, 64, 1, 1]]                  [1, 8, 1, 1]           512      \n",
      "    LeakyReLU-23                  [[1, 8, 1, 1]]                  [1, 8, 1, 1]            0       \n",
      "     Conv2D-85                    [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Conv2D-86                    [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Softmax-14                 [[1, 2, 64, 1, 1]]              [1, 2, 64, 1, 1]          0       \n",
      "       SKFF-5        [[[1, 64, 256, 256], [1, 64, 256, 256]]]  [1, 64, 256, 256]          0       \n",
      "     Conv2D-82                  [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-12                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-12                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-12                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-80                 [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "    Upsample-10                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "       Up-10                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "    UpSample-10                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-83                 [[1, 64, 256, 256]]             [1, 64, 256, 256]        4,096     \n",
      "       MRB-3                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "    AvgPool2D-10               [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-105                [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "      Down-10                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "   DownSample-10               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-11               [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-106                [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "      Down-11                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "   DownSample-11               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-12               [[1, 96, 128, 128]]              [1, 96, 64, 64]           0       \n",
      "     Conv2D-107                 [[1, 96, 64, 64]]               [1, 144, 64, 64]       13,824     \n",
      "      Down-12                  [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "   DownSample-12               [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-90                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       18,432     \n",
      "    LeakyReLU-25               [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-91                 [[1, 64, 256, 256]]             [1, 64, 256, 256]       18,432     \n",
      "     Conv2D-92                 [[1, 64, 256, 256]]              [1, 1, 256, 256]         64       \n",
      "     Softmax-16                  [[1, 1, 65536]]                 [1, 1, 65536]            0       \n",
      "     Conv2D-93                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "    LeakyReLU-26                 [[1, 64, 1, 1]]                 [1, 64, 1, 1]            0       \n",
      "     Conv2D-94                   [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "  ContextBlock-10              [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "       RCB-10                  [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-95                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       41,472     \n",
      "    LeakyReLU-27               [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-96                 [[1, 96, 128, 128]]             [1, 96, 128, 128]       41,472     \n",
      "     Conv2D-97                 [[1, 96, 128, 128]]              [1, 1, 128, 128]         96       \n",
      "     Softmax-17                  [[1, 1, 16384]]                 [1, 1, 16384]            0       \n",
      "     Conv2D-98                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "    LeakyReLU-28                 [[1, 96, 1, 1]]                 [1, 96, 1, 1]            0       \n",
      "     Conv2D-99                   [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "  ContextBlock-11              [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "       RCB-11                  [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-100                 [[1, 144, 64, 64]]              [1, 144, 64, 64]       93,312     \n",
      "    LeakyReLU-29                [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-101                 [[1, 144, 64, 64]]              [1, 144, 64, 64]       93,312     \n",
      "     Conv2D-102                 [[1, 144, 64, 64]]               [1, 1, 64, 64]          144      \n",
      "     Softmax-18                   [[1, 1, 4096]]                  [1, 1, 4096]            0       \n",
      "     Conv2D-103                  [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "    LeakyReLU-30                 [[1, 144, 1, 1]]                [1, 144, 1, 1]           0       \n",
      "     Conv2D-104                  [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "  ContextBlock-12               [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "       RCB-12                   [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-110                 [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-15                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-15                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-15                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "AdaptiveAvgPool2D-8            [[1, 96, 128, 128]]               [1, 96, 1, 1]            0       \n",
      "     Conv2D-116                  [[1, 96, 1, 1]]                 [1, 12, 1, 1]          1,152     \n",
      "    LeakyReLU-32                 [[1, 12, 1, 1]]                 [1, 12, 1, 1]            0       \n",
      "     Conv2D-117                  [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Conv2D-118                  [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Softmax-20                 [[1, 2, 96, 1, 1]]              [1, 2, 96, 1, 1]          0       \n",
      "       SKFF-8        [[[1, 96, 128, 128], [1, 96, 128, 128]]]  [1, 96, 128, 128]          0       \n",
      "     Conv2D-108                [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "    Upsample-13                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "       Up-13                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "    UpSample-13                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "AdaptiveAvgPool2D-7            [[1, 64, 256, 256]]               [1, 64, 1, 1]            0       \n",
      "     Conv2D-113                  [[1, 64, 1, 1]]                  [1, 8, 1, 1]           512      \n",
      "    LeakyReLU-31                  [[1, 8, 1, 1]]                  [1, 8, 1, 1]            0       \n",
      "     Conv2D-114                   [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Conv2D-115                   [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Softmax-19                 [[1, 2, 64, 1, 1]]              [1, 2, 64, 1, 1]          0       \n",
      "       SKFF-7        [[[1, 64, 256, 256], [1, 64, 256, 256]]]  [1, 64, 256, 256]          0       \n",
      "     Conv2D-111                 [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-16                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-16                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-16                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-109                [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "    Upsample-14                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "       Up-14                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "    UpSample-14                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-112                [[1, 64, 256, 256]]             [1, 64, 256, 256]        4,096     \n",
      "       MRB-4                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-119                [[1, 64, 256, 256]]             [1, 64, 256, 256]       36,864     \n",
      "       RRG-2                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "    AvgPool2D-13               [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-135                [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "      Down-13                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "   DownSample-13               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-14               [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-136                [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "      Down-14                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "   DownSample-14               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-15               [[1, 96, 128, 128]]              [1, 96, 64, 64]           0       \n",
      "     Conv2D-137                 [[1, 96, 64, 64]]               [1, 144, 64, 64]       13,824     \n",
      "      Down-15                  [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "   DownSample-15               [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-120                [[1, 64, 256, 256]]             [1, 64, 256, 256]        9,216     \n",
      "    LeakyReLU-33               [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-121                [[1, 64, 256, 256]]             [1, 64, 256, 256]        9,216     \n",
      "     Conv2D-122                [[1, 64, 256, 256]]              [1, 1, 256, 256]         64       \n",
      "     Softmax-21                  [[1, 1, 65536]]                 [1, 1, 65536]            0       \n",
      "     Conv2D-123                  [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "    LeakyReLU-34                 [[1, 64, 1, 1]]                 [1, 64, 1, 1]            0       \n",
      "     Conv2D-124                  [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "  ContextBlock-13              [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "       RCB-13                  [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-125                [[1, 96, 128, 128]]             [1, 96, 128, 128]       20,736     \n",
      "    LeakyReLU-35               [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-126                [[1, 96, 128, 128]]             [1, 96, 128, 128]       20,736     \n",
      "     Conv2D-127                [[1, 96, 128, 128]]              [1, 1, 128, 128]         96       \n",
      "     Softmax-22                  [[1, 1, 16384]]                 [1, 1, 16384]            0       \n",
      "     Conv2D-128                  [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "    LeakyReLU-36                 [[1, 96, 1, 1]]                 [1, 96, 1, 1]            0       \n",
      "     Conv2D-129                  [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "  ContextBlock-14              [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "       RCB-14                  [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-130                 [[1, 144, 64, 64]]              [1, 144, 64, 64]       46,656     \n",
      "    LeakyReLU-37                [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-131                 [[1, 144, 64, 64]]              [1, 144, 64, 64]       46,656     \n",
      "     Conv2D-132                 [[1, 144, 64, 64]]               [1, 1, 64, 64]          144      \n",
      "     Softmax-23                   [[1, 1, 4096]]                  [1, 1, 4096]            0       \n",
      "     Conv2D-133                  [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "    LeakyReLU-38                 [[1, 144, 1, 1]]                [1, 144, 1, 1]           0       \n",
      "     Conv2D-134                  [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "  ContextBlock-15               [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "       RCB-15                   [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-140                 [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-19                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-19                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-19                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "AdaptiveAvgPool2D-10           [[1, 96, 128, 128]]               [1, 96, 1, 1]            0       \n",
      "     Conv2D-146                  [[1, 96, 1, 1]]                 [1, 12, 1, 1]          1,152     \n",
      "    LeakyReLU-40                 [[1, 12, 1, 1]]                 [1, 12, 1, 1]            0       \n",
      "     Conv2D-147                  [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Conv2D-148                  [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Softmax-25                 [[1, 2, 96, 1, 1]]              [1, 2, 96, 1, 1]          0       \n",
      "      SKFF-10        [[[1, 96, 128, 128], [1, 96, 128, 128]]]  [1, 96, 128, 128]          0       \n",
      "     Conv2D-138                [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "    Upsample-17                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "       Up-17                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "    UpSample-17                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "AdaptiveAvgPool2D-9            [[1, 64, 256, 256]]               [1, 64, 1, 1]            0       \n",
      "     Conv2D-143                  [[1, 64, 1, 1]]                  [1, 8, 1, 1]           512      \n",
      "    LeakyReLU-39                  [[1, 8, 1, 1]]                  [1, 8, 1, 1]            0       \n",
      "     Conv2D-144                   [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Conv2D-145                   [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Softmax-24                 [[1, 2, 64, 1, 1]]              [1, 2, 64, 1, 1]          0       \n",
      "       SKFF-9        [[[1, 64, 256, 256], [1, 64, 256, 256]]]  [1, 64, 256, 256]          0       \n",
      "     Conv2D-141                 [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-20                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-20                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-20                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-139                [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "    Upsample-18                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "       Up-18                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "    UpSample-18                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-142                [[1, 64, 256, 256]]             [1, 64, 256, 256]        4,096     \n",
      "       MRB-5                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "    AvgPool2D-16               [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-164                [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "      Down-16                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "   DownSample-16               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-17               [[1, 64, 256, 256]]             [1, 64, 128, 128]          0       \n",
      "     Conv2D-165                [[1, 64, 128, 128]]             [1, 96, 128, 128]        6,144     \n",
      "      Down-17                  [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "   DownSample-17               [[1, 64, 256, 256]]             [1, 96, 128, 128]          0       \n",
      "    AvgPool2D-18               [[1, 96, 128, 128]]              [1, 96, 64, 64]           0       \n",
      "     Conv2D-166                 [[1, 96, 64, 64]]               [1, 144, 64, 64]       13,824     \n",
      "      Down-18                  [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "   DownSample-18               [[1, 96, 128, 128]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-149                [[1, 64, 256, 256]]             [1, 64, 256, 256]        9,216     \n",
      "    LeakyReLU-41               [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-150                [[1, 64, 256, 256]]             [1, 64, 256, 256]        9,216     \n",
      "     Conv2D-151                [[1, 64, 256, 256]]              [1, 1, 256, 256]         64       \n",
      "     Softmax-26                  [[1, 1, 65536]]                 [1, 1, 65536]            0       \n",
      "     Conv2D-152                  [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "    LeakyReLU-42                 [[1, 64, 1, 1]]                 [1, 64, 1, 1]            0       \n",
      "     Conv2D-153                  [[1, 64, 1, 1]]                 [1, 64, 1, 1]          4,096     \n",
      "  ContextBlock-16              [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "       RCB-16                  [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-154                [[1, 96, 128, 128]]             [1, 96, 128, 128]       20,736     \n",
      "    LeakyReLU-43               [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-155                [[1, 96, 128, 128]]             [1, 96, 128, 128]       20,736     \n",
      "     Conv2D-156                [[1, 96, 128, 128]]              [1, 1, 128, 128]         96       \n",
      "     Softmax-27                  [[1, 1, 16384]]                 [1, 1, 16384]            0       \n",
      "     Conv2D-157                  [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "    LeakyReLU-44                 [[1, 96, 1, 1]]                 [1, 96, 1, 1]            0       \n",
      "     Conv2D-158                  [[1, 96, 1, 1]]                 [1, 96, 1, 1]          9,216     \n",
      "  ContextBlock-17              [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "       RCB-17                  [[1, 96, 128, 128]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-159                 [[1, 144, 64, 64]]              [1, 144, 64, 64]       46,656     \n",
      "    LeakyReLU-45                [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-160                 [[1, 144, 64, 64]]              [1, 144, 64, 64]       46,656     \n",
      "     Conv2D-161                 [[1, 144, 64, 64]]               [1, 1, 64, 64]          144      \n",
      "     Softmax-28                   [[1, 1, 4096]]                  [1, 1, 4096]            0       \n",
      "     Conv2D-162                  [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "    LeakyReLU-46                 [[1, 144, 1, 1]]                [1, 144, 1, 1]           0       \n",
      "     Conv2D-163                  [[1, 144, 1, 1]]                [1, 144, 1, 1]        20,736     \n",
      "  ContextBlock-18               [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "       RCB-18                   [[1, 144, 64, 64]]              [1, 144, 64, 64]          0       \n",
      "     Conv2D-169                 [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-23                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-23                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-23                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "AdaptiveAvgPool2D-12           [[1, 96, 128, 128]]               [1, 96, 1, 1]            0       \n",
      "     Conv2D-175                  [[1, 96, 1, 1]]                 [1, 12, 1, 1]          1,152     \n",
      "    LeakyReLU-48                 [[1, 12, 1, 1]]                 [1, 12, 1, 1]            0       \n",
      "     Conv2D-176                  [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Conv2D-177                  [[1, 12, 1, 1]]                 [1, 96, 1, 1]          1,152     \n",
      "     Softmax-30                 [[1, 2, 96, 1, 1]]              [1, 2, 96, 1, 1]          0       \n",
      "      SKFF-12        [[[1, 96, 128, 128], [1, 96, 128, 128]]]  [1, 96, 128, 128]          0       \n",
      "     Conv2D-167                [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "    Upsample-21                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "       Up-21                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "    UpSample-21                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "AdaptiveAvgPool2D-11           [[1, 64, 256, 256]]               [1, 64, 1, 1]            0       \n",
      "     Conv2D-172                  [[1, 64, 1, 1]]                  [1, 8, 1, 1]           512      \n",
      "    LeakyReLU-47                  [[1, 8, 1, 1]]                  [1, 8, 1, 1]            0       \n",
      "     Conv2D-173                   [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Conv2D-174                   [[1, 8, 1, 1]]                 [1, 64, 1, 1]           512      \n",
      "     Softmax-29                 [[1, 2, 64, 1, 1]]              [1, 2, 64, 1, 1]          0       \n",
      "      SKFF-11        [[[1, 64, 256, 256], [1, 64, 256, 256]]]  [1, 64, 256, 256]          0       \n",
      "     Conv2D-170                 [[1, 144, 64, 64]]              [1, 96, 64, 64]        13,824     \n",
      "    Upsample-24                 [[1, 96, 64, 64]]              [1, 96, 128, 128]          0       \n",
      "       Up-24                    [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "    UpSample-24                 [[1, 144, 64, 64]]             [1, 96, 128, 128]          0       \n",
      "     Conv2D-168                [[1, 96, 128, 128]]             [1, 64, 128, 128]        6,144     \n",
      "    Upsample-22                [[1, 64, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "       Up-22                   [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "    UpSample-22                [[1, 96, 128, 128]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-171                [[1, 64, 256, 256]]             [1, 64, 256, 256]        4,096     \n",
      "       MRB-6                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-178                [[1, 64, 256, 256]]             [1, 64, 256, 256]       36,864     \n",
      "       RRG-3                   [[1, 64, 256, 256]]             [1, 64, 256, 256]          0       \n",
      "     Conv2D-179                [[1, 64, 256, 256]]              [1, 3, 256, 256]        1,728     \n",
      "====================================================================================================\n",
      "Total params: 3,120,288\n",
      "Trainable params: 3,120,288\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 4679.46\n",
      "Params size (MB): 11.90\n",
      "Estimated Total Size (MB): 4692.11\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "## Learning Enriched Features for Real Image Restoration and Enhancement\n",
    "## Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Ming-Hsuan Yang, and Ling Shao\n",
    "## ECCV 2020\n",
    "## https://arxiv.org/abs/2003.06792\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# --- Imports --- #\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "from paddle.nn import functional as F\n",
    "\n",
    "##########################################################################\n",
    "##---------- Selective Kernel Feature Fusion (SKFF) ----------\n",
    "class SKFF(nn.Layer):\n",
    "    def __init__(self, in_channels, height=3,reduction=8,bias=False):\n",
    "        super(SKFF, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        d = max(int(in_channels/reduction),4)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2D(1)\n",
    "        self.conv_du = nn.Sequential(nn.Conv2D(in_channels, d, 1, padding=0, bias_attr=bias), nn.LeakyReLU(0.2))\n",
    "\n",
    "        self.fcs = nn.LayerList([])\n",
    "        for i in range(self.height):\n",
    "            self.fcs.append(nn.Conv2D(d, in_channels, kernel_size=1, stride=1,bias_attr=bias))\n",
    "        \n",
    "        self.softmax = nn.Softmax(axis=1)\n",
    "\n",
    "    def forward(self, inp_feats):\n",
    "        batch_size = inp_feats[0].shape[0]\n",
    "        n_feats =  inp_feats[0].shape[1]\n",
    "        \n",
    "\n",
    "        inp_feats = paddle.concat(inp_feats, axis=1)\n",
    "        inp_feats = inp_feats.reshape([batch_size, self.height, n_feats, inp_feats.shape[2], inp_feats.shape[3]])\n",
    "        \n",
    "        feats_U = paddle.sum(inp_feats, axis=1)\n",
    "        feats_S = self.avg_pool(feats_U)\n",
    "        feats_Z = self.conv_du(feats_S)\n",
    "\n",
    "        attention_vectors = [fc(feats_Z) for fc in self.fcs]\n",
    "        attention_vectors = paddle.concat(attention_vectors, axis=1)\n",
    "        attention_vectors = attention_vectors.reshape([batch_size, self.height, n_feats, 1, 1])\n",
    "        # stx()\n",
    "        attention_vectors = self.softmax(attention_vectors)\n",
    "        \n",
    "        feats_V = paddle.sum(inp_feats*attention_vectors, axis=1)\n",
    "        \n",
    "        return feats_V\n",
    "\n",
    "class ContextBlock(nn.Layer):\n",
    "\n",
    "    def __init__(self, n_feat, bias=False):\n",
    "        super(ContextBlock, self).__init__()\n",
    "\n",
    "        self.conv_mask = nn.Conv2D(n_feat, 1, kernel_size=1, bias_attr=bias)\n",
    "        self.softmax = nn.Softmax(axis=2)\n",
    "\n",
    "        self.channel_add_conv = nn.Sequential(\n",
    "            nn.Conv2D(n_feat, n_feat, kernel_size=1, bias_attr=bias),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2D(n_feat, n_feat, kernel_size=1, bias_attr=bias)\n",
    "        )\n",
    "\n",
    "    def modeling(self, x):\n",
    "        batch, channel, height, width = x.shape\n",
    "        input_x = x\n",
    "        # [N, C, H * W]\n",
    "        input_x = input_x.reshape([batch, channel, height * width])\n",
    "        # [N, 1, C, H * W]\n",
    "        input_x = input_x.unsqueeze(1)\n",
    "        # [N, 1, H, W]\n",
    "        context_mask = self.conv_mask(x)\n",
    "        # [N, 1, H * W]\n",
    "        context_mask = context_mask.reshape([batch, 1, height * width])\n",
    "        # [N, 1, H * W]\n",
    "        context_mask = self.softmax(context_mask)\n",
    "        # [N, 1, H * W, 1]\n",
    "        context_mask = context_mask.unsqueeze(3)\n",
    "        # [N, 1, C, 1]\n",
    "        context = paddle.matmul(input_x, context_mask)\n",
    "        # [N, C, 1, 1]\n",
    "        context = context.reshape([batch, channel, 1, 1])\n",
    "\n",
    "        return context\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [N, C, 1, 1]\n",
    "        context = self.modeling(x)\n",
    "\n",
    "        # [N, C, 1, 1]\n",
    "        channel_add_term = self.channel_add_conv(context)\n",
    "        x = x + channel_add_term\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "##---------- Spatial Attention ----------\n",
    "class RCB(nn.Layer):\n",
    "    def __init__(self, n_feat, kernel_size=3, reduction=8, bias=False, groups=1):\n",
    "        super(RCB, self).__init__()\n",
    "\n",
    "        act = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2D(n_feat, n_feat, kernel_size=3, stride=1, padding=1, bias_attr=bias, groups=groups),\n",
    "            act,\n",
    "            nn.Conv2D(n_feat, n_feat, kernel_size=3, stride=1, padding=1, bias_attr=bias, groups=groups)\n",
    "        )\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "        self.gcnet = ContextBlock(n_feat, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        res = self.act(self.gcnet(res))\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "##---------- Resizing Layers ----------    \n",
    "class Down(nn.Layer):\n",
    "    def __init__(self, in_channels, chan_factor, bias=False):\n",
    "        super(Down, self).__init__()\n",
    "\n",
    "        self.bot = nn.Sequential(\n",
    "            nn.AvgPool2D(2, ceil_mode=True, exclusive=False),\n",
    "            nn.Conv2D(in_channels, int(in_channels * chan_factor), 1, stride=1, padding=0, bias_attr=bias)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bot(x)\n",
    "\n",
    "\n",
    "class DownSample(nn.Layer):\n",
    "    def __init__(self, in_channels, scale_factor, chan_factor=2, kernel_size=3):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.scale_factor = int(np.log2(scale_factor))\n",
    "\n",
    "        Layers_body = []\n",
    "        for i in range(self.scale_factor):\n",
    "            Layers_body.append(Down(in_channels, chan_factor))\n",
    "            in_channels = int(in_channels * chan_factor)\n",
    "\n",
    "        self.body = nn.Sequential(*Layers_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(nn.Layer):\n",
    "    def __init__(self, in_channels, chan_factor, bias=False):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        self.bot = nn.Sequential(\n",
    "            nn.Conv2D(in_channels, int(in_channels // chan_factor), 1, stride=1, padding=0, bias_attr=bias),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=bias)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bot(x)\n",
    "\n",
    "\n",
    "class UpSample(nn.Layer):\n",
    "    def __init__(self, in_channels, scale_factor, chan_factor=2, kernel_size=3):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.scale_factor = int(np.log2(scale_factor))\n",
    "\n",
    "        Layers_body = []\n",
    "        for i in range(self.scale_factor):\n",
    "            Layers_body.append(Up(in_channels, chan_factor))\n",
    "            in_channels = int(in_channels // chan_factor)\n",
    "\n",
    "        self.body = nn.Sequential(*Layers_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "class GRU_sample(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(GRU_sample, self).__init__()\n",
    "    def forward(self,x,h_t_1):\n",
    "        C = x.shape[1]\n",
    "        z_t = F.sigmoid(x + h_t_1)\n",
    "        h_hat_t = F.tanh(x + paddle.matmul(z_t, h_t_1))\n",
    "        h_t = paddle.matmul((1 - z_t), h_t_1) + paddle.matmul(z_t, h_hat_t)\n",
    "        #conv = nn.Conv2d(in_channels=C, out_channels=C, kernel_size=1, stride=1) \n",
    "        conv = nn.Conv2D(C, C, 1, stride=1, padding=0, bias_attr=False)\n",
    "        y = conv(h_t)\n",
    "        return y, h_t \n",
    "\n",
    "##---------- Multi-Scale Resiudal Block (MRB) ----------\n",
    "class MRB(nn.Layer):\n",
    "    def __init__(self, n_feat, height, width, chan_factor, bias, groups):\n",
    "        super(MRB, self).__init__()\n",
    "\n",
    "        self.n_feat, self.height, self.width = n_feat, height, width\n",
    "\n",
    "        self.dau_top = RCB(int(n_feat * chan_factor ** 0), bias=bias, groups=groups)\n",
    "        self.dau_mid = RCB(int(n_feat * chan_factor ** 1), bias=bias, groups=groups)\n",
    "        self.dau_bot = RCB(int(n_feat * chan_factor ** 2), bias=bias, groups=groups)\n",
    "\n",
    "        self.down2 = DownSample(int((chan_factor ** 0) * n_feat), 2, chan_factor)\n",
    "        self.down4 = nn.Sequential(\n",
    "            DownSample(int((chan_factor ** 0) * n_feat), 2, chan_factor),\n",
    "            DownSample(int((chan_factor ** 1) * n_feat), 2, chan_factor)\n",
    "        )\n",
    "\n",
    "        self.up21_1 = UpSample(int((chan_factor ** 1) * n_feat), 2, chan_factor)\n",
    "        self.up21_2 = UpSample(int((chan_factor ** 1) * n_feat), 2, chan_factor)\n",
    "        self.up32_1 = UpSample(int((chan_factor ** 2) * n_feat), 2, chan_factor)\n",
    "        self.up32_2 = UpSample(int((chan_factor ** 2) * n_feat), 2, chan_factor)\n",
    "\n",
    "        self.conv_out = nn.Conv2D(n_feat, n_feat, kernel_size=1, padding=0, bias_attr=bias)\n",
    "\n",
    "        # only two inputs for SKFF\n",
    "        self.skff_top = SKFF(int(n_feat * chan_factor ** 0), 2)\n",
    "        self.skff_mid = SKFF(int(n_feat * chan_factor ** 1), 2)\n",
    "        self.convGru = GRU_sample()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_top = x.clone()\n",
    "        x_mid = self.down2(x_top)\n",
    "        x_bot = self.down4(x_top)\n",
    "\n",
    "        x_top = self.dau_top(x_top)\n",
    "        x_mid = self.dau_mid(x_mid)\n",
    "        x_bot = self.dau_bot(x_bot)\n",
    "\n",
    "        x_mid = self.skff_mid([x_mid, self.up32_1(x_bot)])\n",
    "        x_top = self.skff_top([x_top, self.up21_1(x_mid)])\n",
    "\n",
    "        x_top = self.dau_top(x_top)\n",
    "        x_mid = self.dau_mid(x_mid)\n",
    "        x_bot = self.dau_bot(x_bot)\n",
    "        x_mid = self.skff_mid([x_mid, self.up32_2(x_bot)])\n",
    "        # x_m,x_up = self.convGru(x_mid, self.up32_2(x_bot)) # add\n",
    "        # x_mid = self.skff_mid([x_m, x_up])\n",
    "        x_top = self.skff_top([x_top, self.up21_2(x_mid)])\n",
    "        \n",
    "\n",
    "        out = self.conv_out(x_top)\n",
    "        out = out + x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "##---------- Recursive Residual Group (RRG) ----------\n",
    "class RRG(nn.Layer):\n",
    "    def __init__(self, n_feat, n_MRB, height, width, chan_factor, bias=False, groups=1):\n",
    "        super(RRG, self).__init__()\n",
    "\n",
    "        Layers_body = [MRB(n_feat, height, width, chan_factor, bias, groups) for _ in range(n_MRB)]\n",
    "        Layers_body.append(nn.Conv2D(n_feat, n_feat, kernel_size=3, stride=1, padding=1, bias_attr=bias))\n",
    "        self.body = nn.Sequential(*Layers_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "##---------- MIRNet_V2  -----------------------\n",
    "class MIRNet_v2(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 inp_channels=3,\n",
    "                 out_channels=3,\n",
    "                 n_feat=80,\n",
    "                 chan_factor=1.5,\n",
    "                 n_MRB=2,\n",
    "                 height=3,\n",
    "                 width=2,\n",
    "                 bias=False,\n",
    "                 task=None\n",
    "                 ):\n",
    "        super(MIRNet_v2, self).__init__()\n",
    "        nn.initializer.set_global_initializer(nn.initializer.KaimingNormal(fan_in=10000.), nn.initializer.Constant(0.0))\n",
    "\n",
    "        self.task = task\n",
    "        self.conv_in = nn.Conv2D(inp_channels, n_feat, kernel_size=3, padding=1, bias_attr=bias)\n",
    "\n",
    "        layers_body = []\n",
    "\n",
    "        layers_body.append(RRG(n_feat, n_MRB, height, width, chan_factor, bias, groups=1))\n",
    "        layers_body.append(RRG(n_feat, n_MRB, height, width, chan_factor, bias, groups=2))\n",
    "        layers_body.append(RRG(n_feat, n_MRB, height, width, chan_factor, bias, groups=4))\n",
    "        # layers_body.append(RRG(n_feat, n_MRB, height, width, chan_factor, bias, groups=4))\n",
    "\n",
    "        self.body = nn.Sequential(*layers_body)\n",
    "\n",
    "        self.conv_out = nn.Conv2D(n_feat, out_channels, kernel_size=3, padding=1, bias_attr=bias)\n",
    "\n",
    "    def forward(self, inp_img):\n",
    "        shallow_feats = self.conv_in(inp_img)\n",
    "        deep_feats = self.body(shallow_feats)\n",
    "\n",
    "        if self.task == 'defocus_deblurring':\n",
    "            deep_feats += shallow_feats\n",
    "            out_img = self.conv_out(deep_feats)\n",
    "\n",
    "        else:\n",
    "            out_img = self.conv_out(deep_feats)\n",
    "            out_img += inp_img\n",
    "\n",
    "        return out_img\n",
    "if __name__ == \"__main__\":\n",
    "    model = MIRNet_v2(n_feat=64)\n",
    "    paddle.summary(model, (1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.定义loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T15:23:24.298896Z",
     "iopub.status.busy": "2022-09-06T15:23:24.298053Z",
     "iopub.status.idle": "2022-09-06T15:23:24.325569Z",
     "shell.execute_reply": "2022-09-06T15:23:24.324918Z",
     "shell.execute_reply.started": "2022-09-06T15:23:24.298853Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle.nn.functional as F\n",
    "\n",
    "def gaussian1d(window_size, sigma):\n",
    "    ###window_size = 11\n",
    "    x = paddle.arange(window_size,dtype='float32')\n",
    "    x = x - window_size//2\n",
    "    gauss = paddle.exp(-x ** 2 / float(2 * sigma ** 2))\n",
    "    # print('gauss.size():', gauss.size())\n",
    "    ### torch.Size([11])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, sigma, channel):\n",
    "    _1D_window = gaussian1d(window_size, sigma).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).unsqueeze(0).unsqueeze(0)\n",
    "    # print('2d',_2D_window.shape)\n",
    "    # print(window_size, sigma, channel)\n",
    "    return _2D_window.expand([channel,1,window_size,window_size])\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel=3 ,data_range = 255.,size_average=True,C=None):\n",
    "    # size_average for different channel\n",
    "\n",
    "    padding = window_size // 2\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padding, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padding, groups=channel)\n",
    "    # print(mu1.shape)\n",
    "    # print(mu1[0,0])\n",
    "    # print(mu1.mean())\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padding, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padding, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padding, groups=channel) - mu1_mu2\n",
    "    if C ==None:\n",
    "        C1 = (0.01*data_range) ** 2\n",
    "        C2 = (0.03*data_range) ** 2\n",
    "    else:\n",
    "        C1 = (C[0]*data_range) ** 2\n",
    "        C2 = (C[1]*data_range) ** 2\n",
    "    # l = (2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1)\n",
    "    # ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    sc = (2 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    lsc = ((2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1))*sc\n",
    "\n",
    "    if size_average:\n",
    "        ### ssim_map.mean()是对这个tensor里面的所有的数值求平均\n",
    "        return lsc.mean()\n",
    "    else:\n",
    "        # ## 返回各个channel的值\n",
    "        return lsc.flatten(2).mean(-1),sc.flatten(2).mean(-1)\n",
    "\n",
    "def ms_ssim(\n",
    "    img1, img2,window, data_range=255, size_average=True, window_size=11, channel=3, sigma=1.5, weights=None, C=(0.01, 0.03)\n",
    "):\n",
    "\n",
    "    r\"\"\" interface of ms-ssim\n",
    "    Args:\n",
    "        img1 (torch.Tensor): a batch of images, (N,C,[T,]H,W)\n",
    "        img2 (torch.Tensor): a batch of images, (N,C,[T,]H,W)\n",
    "        data_range (float or int, optional): value range of input images. (usually 1.0 or 255)\n",
    "        size_average (bool, optional): if size_average=True, ssim of all images will be averaged as a scalar\n",
    "        win_size: (int, optional): the size of gauss kernel\n",
    "        win_sigma: (float, optional): sigma of normal distribution\n",
    "        win (torch.Tensor, optional): 1-D gauss kernel. if None, a new kernel will be created according to win_size and win_sigma\n",
    "        weights (list, optional): weights for different levels\n",
    "        K (list or tuple, optional): scalar constants (K1, K2). Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.\n",
    "    Returns:\n",
    "        torch.Tensor: ms-ssim results\n",
    "    \"\"\"\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError(\"Input images should have the same dimensions.\")\n",
    "\n",
    "    # for d in range(len(img1.shape) - 1, 1, -1):\n",
    "    #     img1 = img1.squeeze(dim=d)\n",
    "    #     img2 = img2.squeeze(dim=d)\n",
    "\n",
    "    if not img1.dtype == img2.dtype:\n",
    "        raise ValueError(\"Input images should have the same dtype.\")\n",
    "\n",
    "    if len(img1.shape) == 4:\n",
    "        avg_pool = F.avg_pool2d\n",
    "    elif len(img1.shape) == 5:\n",
    "        avg_pool = F.avg_pool3d\n",
    "    else:\n",
    "        raise ValueError(f\"Input images should be 4-d or 5-d tensors, but got {img1.shape}\")\n",
    "\n",
    "    smaller_side = min(img1.shape[-2:])\n",
    "\n",
    "    assert smaller_side > (window_size - 1) * (2 ** 4), \"Image size should be larger than %d due to the 4 downsamplings \" \\\n",
    "                                                        \"with window_size %d in ms-ssim\" % ((window_size - 1) * (2 ** 4),window_size)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = [0.0448, 0.2856, 0.3001, 0.2363, 0.1333]\n",
    "    weights = paddle.to_tensor(weights)\n",
    "\n",
    "    if window is None:\n",
    "        window = create_window(window_size, sigma, channel)\n",
    "    assert window.shape == [channel, 1, window_size, window_size], \" window.shape error\"\n",
    "\n",
    "    levels = weights.shape[0] # 5\n",
    "    mcs = []\n",
    "    for i in range(levels):\n",
    "        ssim_per_channel, cs =  _ssim(img1, img2, window=window, window_size=window_size,\n",
    "                                       channel=3, data_range=data_range,C=C, size_average=False)\n",
    "        if i < levels - 1:\n",
    "            mcs.append(F.relu(cs))\n",
    "            padding = [s % 2 for s in img1.shape[2:]]\n",
    "            img1 = avg_pool(img1, kernel_size=2, padding=padding)\n",
    "            img2 = avg_pool(img2, kernel_size=2, padding=padding)\n",
    "\n",
    "    ssim_per_channel = F.relu(ssim_per_channel)  # (batch, channel)\n",
    "    mcs_and_ssim = paddle.stack(mcs + [ssim_per_channel], axis=0)  # (level, batch, channel) 按照等级堆叠\n",
    "    ms_ssim_val = paddle.prod(mcs_and_ssim ** weights.reshape([-1, 1, 1]), axis=0) # level 相乘\n",
    "    print(ms_ssim_val.shape)\n",
    "    if size_average:\n",
    "        return ms_ssim_val.mean()\n",
    "    else:\n",
    "        # 返回各个channel的值\n",
    "        return ms_ssim_val.flatten(2).mean(1)\n",
    "\n",
    "\n",
    "class SSIMLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self, window_size=11, channel=3, data_range=255., sigma=1.5):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super(SSIMLoss, self).__init__()\n",
    "       self.data_range = data_range\n",
    "       self.C = [0.01, 0.03]\n",
    "       self.window_size = window_size\n",
    "       self.channel = channel\n",
    "       self.sigma = sigma\n",
    "       self.window = create_window(self.window_size, self.sigma, self.channel)\n",
    "       # print(self.window_size,self.window.shape)\n",
    "   def forward(self, input, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       # output = xxxxx\n",
    "       # return output\n",
    "       return 1-_ssim(input, label,data_range = self.data_range,\n",
    "                      window = self.window, window_size=self.window_size, channel=3,\n",
    "                      size_average=True,C=self.C)\n",
    "\n",
    "class MS_SSIMLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self,data_range=255., channel=3, window_size=11, sigma=1.5):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super(MS_SSIMLoss, self).__init__()\n",
    "       self.data_range = data_range\n",
    "       self.C = [0.01, 0.03]\n",
    "       self.window_size = window_size\n",
    "       self.channel = channel\n",
    "       self.sigma = sigma\n",
    "       self.window = create_window(self.window_size, self.sigma, self.channel)\n",
    "       # print(self.window_size,self.window.shape)\n",
    "   def forward(self, input, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       # output = xxxxx\n",
    "       # return output\n",
    "       return 1-ms_ssim(input, label, data_range=self.data_range,\n",
    "                      window = self.window, window_size=self.window_size, channel=self.channel,\n",
    "                      size_average=True,  sigma=self.sigma,\n",
    "                      weights=None, C=self.C)\n",
    "\n",
    "class PSNRLoss(paddle.nn.Layer):\n",
    "   def __init__(self):\n",
    "       super(PSNRLoss, self).__init__()\n",
    "\n",
    "   def forward(self, input, label):\n",
    "       return 100 - 20 * paddle.log10( ((input - label)**2).mean(axis = [1,2,3])**-0.5 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T15:23:28.773345Z",
     "iopub.status.busy": "2022-09-06T15:23:28.772487Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "epoch: 0, batch: 0,loss1 is: [27.032911],loss2 is: [77.45364], loss is: [52.24328] \n",
      "epoch: 0, batch: 1,loss1 is: [36.336334],loss2 is: [79.37695], loss is: [57.856644] \n",
      "epoch: 0, batch: 2,loss1 is: [1.7333329],loss2 is: [74.36154], loss is: [38.047436] \n",
      "epoch: 0, batch: 3,loss1 is: [42.632698],loss2 is: [73.25308], loss is: [57.94289] \n",
      "epoch: 0, batch: 4,loss1 is: [65.10925],loss2 is: [73.62608], loss is: [69.36767] \n",
      "epoch: 0, batch: 5,loss1 is: [56.12868],loss2 is: [77.014305], loss is: [66.571495] \n",
      "epoch: 0, batch: 6,loss1 is: [125.44846],loss2 is: [84.18031], loss is: [104.81439] \n",
      "epoch: 0, batch: 7,loss1 is: [35.99113],loss2 is: [78.93207], loss is: [57.4616] \n",
      "epoch: 0, batch: 8,loss1 is: [117.9074],loss2 is: [82.624626], loss is: [100.266014] \n",
      "epoch: 0, batch: 9,loss1 is: [25.478722],loss2 is: [71.43649], loss is: [48.457607] \n",
      "epoch: 0, batch: 10,loss1 is: [28.5033],loss2 is: [68.9775], loss is: [48.740402] \n",
      "epoch: 0, batch: 11,loss1 is: [32.20731],loss2 is: [68.219025], loss is: [50.213165] \n",
      "epoch: 0, batch: 12,loss1 is: [97.025185],loss2 is: [80.26671], loss is: [88.64595] \n",
      "epoch: 0, batch: 13,loss1 is: [71.288315],loss2 is: [77.97069], loss is: [74.6295] \n",
      "epoch: 0, batch: 14,loss1 is: [108.60387],loss2 is: [81.89787], loss is: [95.25087] \n",
      "epoch: 0, batch: 15,loss1 is: [1.1845827],loss2 is: [65.83296], loss is: [33.508774] \n",
      "epoch: 0, batch: 16,loss1 is: [68.81091],loss2 is: [79.16551], loss is: [73.98821] \n",
      "epoch: 0, batch: 17,loss1 is: [69.550995],loss2 is: [80.82457], loss is: [75.18778] \n",
      "epoch: 0, batch: 18,loss1 is: [50.115646],loss2 is: [74.12467], loss is: [62.12016] \n",
      "epoch: 0, batch: 19,loss1 is: [99.282295],loss2 is: [81.85715], loss is: [90.56972] \n",
      "epoch: 0, batch: 20,loss1 is: [0.25349855],loss2 is: [63.629547], loss is: [31.941523] \n",
      "epoch: 0, batch: 21,loss1 is: [39.63843],loss2 is: [69.59768], loss is: [54.618057] \n",
      "epoch: 0, batch: 22,loss1 is: [19.50237],loss2 is: [65.47998], loss is: [42.491177] \n",
      "epoch: 0, batch: 23,loss1 is: [52.552998],loss2 is: [78.22557], loss is: [65.38928] \n",
      "epoch: 0, batch: 24,loss1 is: [11.886061],loss2 is: [69.11869], loss is: [40.502377] \n",
      "epoch: 0, batch: 25,loss1 is: [41.806103],loss2 is: [66.88382], loss is: [54.344963] \n",
      "epoch: 0, batch: 26,loss1 is: [65.30935],loss2 is: [71.88132], loss is: [68.59534] \n",
      "epoch: 0, batch: 27,loss1 is: [74.38722],loss2 is: [78.55117], loss is: [76.46919] \n",
      "epoch: 0, batch: 28,loss1 is: [47.911762],loss2 is: [80.30721], loss is: [64.10949] \n",
      "epoch: 0, batch: 29,loss1 is: [37.091106],loss2 is: [68.952484], loss is: [53.021797] \n",
      "epoch: 0, batch: 30,loss1 is: [51.53638],loss2 is: [67.03973], loss is: [59.288055] \n",
      "epoch: 0, batch: 31,loss1 is: [59.12274],loss2 is: [78.714905], loss is: [68.91882] \n",
      "epoch: 0, batch: 32,loss1 is: [52.390636],loss2 is: [74.79291], loss is: [63.591774] \n",
      "epoch: 0, batch: 33,loss1 is: [26.9278],loss2 is: [71.23212], loss is: [49.079956] \n",
      "epoch: 0, batch: 34,loss1 is: [83.27115],loss2 is: [74.56601], loss is: [78.91858] \n",
      "epoch: 0, batch: 35,loss1 is: [47.472538],loss2 is: [78.83064], loss is: [63.15159] \n",
      "epoch: 0, batch: 36,loss1 is: [43.755264],loss2 is: [79.7022], loss is: [61.728733] \n",
      "epoch: 0, batch: 37,loss1 is: [104.98827],loss2 is: [86.09776], loss is: [95.543015] \n",
      "epoch: 0, batch: 38,loss1 is: [73.77854],loss2 is: [73.772415], loss is: [73.77548] \n",
      "epoch: 0, batch: 39,loss1 is: [34.194767],loss2 is: [75.25908], loss is: [54.72692] \n",
      "epoch: 0, batch: 40,loss1 is: [14.19574],loss2 is: [67.53366], loss is: [40.8647] \n",
      "epoch: 0, batch: 41,loss1 is: [109.637886],loss2 is: [85.573166], loss is: [97.60553] \n",
      "epoch: 0, batch: 42,loss1 is: [1.0841787],loss2 is: [60.075962], loss is: [30.58007] \n",
      "epoch: 0, batch: 43,loss1 is: [58.410347],loss2 is: [73.16052], loss is: [65.78543] \n",
      "epoch: 0, batch: 44,loss1 is: [64.4356],loss2 is: [72.68024], loss is: [68.55792] \n",
      "epoch: 0, batch: 45,loss1 is: [88.44712],loss2 is: [79.84093], loss is: [84.14403] \n",
      "epoch: 0, batch: 46,loss1 is: [6.5281096],loss2 is: [66.905396], loss is: [36.71675] \n",
      "epoch: 0, batch: 47,loss1 is: [13.72546],loss2 is: [69.04979], loss is: [41.387627] \n",
      "epoch: 0, batch: 48,loss1 is: [128.9314],loss2 is: [83.67506], loss is: [106.30322] \n",
      "epoch: 0, batch: 49,loss1 is: [0.54496527],loss2 is: [63.914], loss is: [32.229485] \n",
      "epoch: 0, batch: 50,loss1 is: [102.70169],loss2 is: [78.05505], loss is: [90.37837] \n",
      "epoch: 0, batch: 51,loss1 is: [81.12881],loss2 is: [77.576416], loss is: [79.352615] \n",
      "epoch: 0, batch: 52,loss1 is: [0.16844273],loss2 is: [61.19671], loss is: [30.682575] \n",
      "epoch: 0, batch: 53,loss1 is: [21.37077],loss2 is: [68.413536], loss is: [44.89215] \n",
      "epoch: 0, batch: 54,loss1 is: [74.84722],loss2 is: [72.224464], loss is: [73.53584] \n",
      "epoch: 0, batch: 55,loss1 is: [23.890734],loss2 is: [61.9566], loss is: [42.923668] \n",
      "epoch: 0, batch: 56,loss1 is: [32.24677],loss2 is: [70.944244], loss is: [51.595505] \n",
      "epoch: 0, batch: 57,loss1 is: [86.603226],loss2 is: [75.044914], loss is: [80.824066] \n",
      "epoch: 0, batch: 58,loss1 is: [71.14726],loss2 is: [78.777794], loss is: [74.962524] \n",
      "epoch: 0, batch: 59,loss1 is: [3.0117333],loss2 is: [70.58536], loss is: [36.798546] \n",
      "epoch: 0, batch: 60,loss1 is: [35.965683],loss2 is: [74.71388], loss is: [55.339783] \n",
      "epoch: 0, batch: 61,loss1 is: [0.11849403],loss2 is: [63.23441], loss is: [31.676453] \n",
      "epoch: 0, batch: 62,loss1 is: [43.304382],loss2 is: [77.20216], loss is: [60.253273] \n",
      "epoch: 0, batch: 63,loss1 is: [106.73711],loss2 is: [80.73627], loss is: [93.73669] \n",
      "epoch: 0, batch: 64,loss1 is: [51.408768],loss2 is: [67.296295], loss is: [59.35253] \n",
      "epoch: 0, batch: 65,loss1 is: [11.850357],loss2 is: [63.383694], loss is: [37.617027] \n",
      "epoch: 0, batch: 66,loss1 is: [65.94008],loss2 is: [68.1764], loss is: [67.05824] \n",
      "epoch: 0, batch: 67,loss1 is: [71.22588],loss2 is: [77.66586], loss is: [74.44588] \n",
      "epoch: 0, batch: 68,loss1 is: [108.58661],loss2 is: [77.91531], loss is: [93.25096] \n",
      "epoch: 0, batch: 69,loss1 is: [33.107906],loss2 is: [71.309814], loss is: [52.208862] \n",
      "epoch: 0, batch: 70,loss1 is: [154.66452],loss2 is: [84.665634], loss is: [119.66508] \n",
      "epoch: 0, batch: 71,loss1 is: [23.43148],loss2 is: [70.673744], loss is: [47.052612] \n",
      "epoch: 0, batch: 72,loss1 is: [58.013557],loss2 is: [80.25278], loss is: [69.13316] \n",
      "epoch: 0, batch: 73,loss1 is: [2.990961],loss2 is: [57.50096], loss is: [30.24596] \n",
      "epoch: 0, batch: 74,loss1 is: [47.09804],loss2 is: [65.006645], loss is: [56.052345] \n",
      "epoch: 0, batch: 75,loss1 is: [5.92798],loss2 is: [65.22698], loss is: [35.57748] \n",
      "epoch: 0, batch: 76,loss1 is: [0.16382337],loss2 is: [60.314213], loss is: [30.239017] \n",
      "epoch: 0, batch: 77,loss1 is: [25.547981],loss2 is: [73.67214], loss is: [49.61006] \n",
      "epoch: 0, batch: 78,loss1 is: [8.648485],loss2 is: [64.167755], loss is: [36.40812] \n",
      "epoch: 0, batch: 79,loss1 is: [67.291435],loss2 is: [79.00037], loss is: [73.145905] \n",
      "epoch: 0, batch: 80,loss1 is: [0.1065731],loss2 is: [49.666866], loss is: [24.886719] \n",
      "epoch: 0, batch: 81,loss1 is: [18.672853],loss2 is: [62.749718], loss is: [40.711285] \n",
      "epoch: 0, batch: 82,loss1 is: [20.121902],loss2 is: [67.74773], loss is: [43.934814] \n",
      "epoch: 0, batch: 83,loss1 is: [66.67644],loss2 is: [70.95151], loss is: [68.81397] \n",
      "epoch: 0, batch: 84,loss1 is: [38.133175],loss2 is: [75.31087], loss is: [56.722023] \n",
      "epoch: 0, batch: 85,loss1 is: [43.814747],loss2 is: [70.48491], loss is: [57.149826] \n",
      "epoch: 0, batch: 86,loss1 is: [128.07137],loss2 is: [82.67167], loss is: [105.37152] \n",
      "epoch: 0, batch: 87,loss1 is: [43.95199],loss2 is: [77.64245], loss is: [60.79722] \n",
      "epoch: 0, batch: 88,loss1 is: [36.601246],loss2 is: [77.28894], loss is: [56.94509] \n",
      "epoch: 0, batch: 89,loss1 is: [55.318535],loss2 is: [75.19852], loss is: [65.25853] \n",
      "epoch: 0, batch: 90,loss1 is: [0.08967519],loss2 is: [53.18158], loss is: [26.635628] \n",
      "epoch: 0, batch: 91,loss1 is: [57.560265],loss2 is: [77.229294], loss is: [67.394775] \n",
      "epoch: 0, batch: 92,loss1 is: [33.84799],loss2 is: [74.241066], loss is: [54.044525] \n",
      "epoch: 0, batch: 93,loss1 is: [92.9088],loss2 is: [82.7684], loss is: [87.8386] \n",
      "epoch: 0, batch: 94,loss1 is: [73.043434],loss2 is: [79.39058], loss is: [76.21701] \n",
      "epoch: 0, batch: 95,loss1 is: [40.58236],loss2 is: [73.01231], loss is: [56.797333] \n",
      "epoch: 0, batch: 96,loss1 is: [87.122116],loss2 is: [82.01449], loss is: [84.5683] \n",
      "epoch: 0, batch: 97,loss1 is: [86.1825],loss2 is: [71.0591], loss is: [78.620804] \n",
      "epoch: 0, batch: 98,loss1 is: [7.704109],loss2 is: [59.68685], loss is: [33.69548] \n",
      "epoch: 0, batch: 99,loss1 is: [82.04889],loss2 is: [81.31102], loss is: [81.679955] \n",
      "epoch: 0, batch: 100,loss1 is: [78.051865],loss2 is: [73.55095], loss is: [75.80141] \n",
      "epoch: 0, batch: 101,loss1 is: [92.44299],loss2 is: [75.431366], loss is: [83.93718] \n",
      "epoch: 0, batch: 102,loss1 is: [51.96604],loss2 is: [76.26921], loss is: [64.11763] \n",
      "epoch: 0, batch: 103,loss1 is: [33.118187],loss2 is: [68.85104], loss is: [50.984615] \n",
      "epoch: 0, batch: 104,loss1 is: [44.356583],loss2 is: [72.11193], loss is: [58.234257] \n",
      "epoch: 0, batch: 105,loss1 is: [76.76813],loss2 is: [79.16527], loss is: [77.9667] \n",
      "epoch: 0, batch: 106,loss1 is: [0.11339784],loss2 is: [47.27237], loss is: [23.692884] \n",
      "epoch: 0, batch: 107,loss1 is: [23.217768],loss2 is: [64.69203], loss is: [43.9549] \n",
      "epoch: 0, batch: 108,loss1 is: [0.04556775],loss2 is: [55.61571], loss is: [27.830639] \n",
      "epoch: 0, batch: 109,loss1 is: [43.19674],loss2 is: [65.40926], loss is: [54.303] \n",
      "epoch: 0, batch: 110,loss1 is: [84.2424],loss2 is: [73.36014], loss is: [78.80127] \n",
      "epoch: 0, batch: 111,loss1 is: [33.950447],loss2 is: [63.299606], loss is: [48.625027] \n",
      "epoch: 0, batch: 112,loss1 is: [85.425766],loss2 is: [82.42473], loss is: [83.92525] \n",
      "epoch: 0, batch: 113,loss1 is: [53.519966],loss2 is: [78.996895], loss is: [66.25843] \n",
      "epoch: 0, batch: 114,loss1 is: [114.22357],loss2 is: [84.19995], loss is: [99.21176] \n",
      "epoch: 0, batch: 115,loss1 is: [69.4496],loss2 is: [68.82424], loss is: [69.13692] \n",
      "epoch: 0, batch: 116,loss1 is: [12.652636],loss2 is: [69.73053], loss is: [41.19158] \n",
      "epoch: 0, batch: 117,loss1 is: [90.71303],loss2 is: [81.04577], loss is: [85.879395] \n",
      "epoch: 0, batch: 118,loss1 is: [36.794514],loss2 is: [74.042656], loss is: [55.418587] \n",
      "epoch: 0, batch: 119,loss1 is: [71.91527],loss2 is: [79.02307], loss is: [75.46917] \n",
      "epoch: 0, batch: 120,loss1 is: [47.386677],loss2 is: [73.21987], loss is: [60.303276] \n",
      "epoch: 0, batch: 121,loss1 is: [8.414745],loss2 is: [64.50009], loss is: [36.45742] \n",
      "epoch: 0, batch: 122,loss1 is: [87.040184],loss2 is: [79.87944], loss is: [83.45981] \n",
      "epoch: 0, batch: 123,loss1 is: [10.819793],loss2 is: [62.109455], loss is: [36.464622] \n",
      "epoch: 0, batch: 124,loss1 is: [79.40227],loss2 is: [69.52354], loss is: [74.462906] \n",
      "epoch: 0, batch: 125,loss1 is: [15.552282],loss2 is: [69.16203], loss is: [42.35716] \n",
      "epoch: 0, batch: 126,loss1 is: [59.569],loss2 is: [76.27218], loss is: [67.92059] \n",
      "epoch: 0, batch: 127,loss1 is: [10.747642],loss2 is: [65.05364], loss is: [37.900642] \n",
      "epoch: 0, batch: 128,loss1 is: [70.9337],loss2 is: [80.99881], loss is: [75.966255] \n",
      "epoch: 0, batch: 129,loss1 is: [0.10538101],loss2 is: [55.54678], loss is: [27.82608] \n",
      "epoch: 0, batch: 130,loss1 is: [43.280838],loss2 is: [64.90135], loss is: [54.091095] \n",
      "epoch: 0, batch: 131,loss1 is: [108.57374],loss2 is: [81.994095], loss is: [95.28392] \n",
      "epoch: 0, batch: 132,loss1 is: [36.44353],loss2 is: [75.07956], loss is: [55.761543] \n",
      "epoch: 0, batch: 133,loss1 is: [45.69745],loss2 is: [62.11713], loss is: [53.907288] \n",
      "epoch: 0, batch: 134,loss1 is: [98.77619],loss2 is: [68.37137], loss is: [83.57378] \n",
      "epoch: 0, batch: 135,loss1 is: [45.437485],loss2 is: [65.908806], loss is: [55.673145] \n",
      "epoch: 0, batch: 136,loss1 is: [22.939861],loss2 is: [63.02782], loss is: [42.98384] \n",
      "epoch: 0, batch: 137,loss1 is: [0.07364154],loss2 is: [52.265865], loss is: [26.169754] \n",
      "epoch: 0, batch: 138,loss1 is: [2.5848746],loss2 is: [58.032112], loss is: [30.308493] \n",
      "epoch: 0, batch: 139,loss1 is: [70.86372],loss2 is: [64.78958], loss is: [67.82665] \n",
      "epoch: 0, batch: 140,loss1 is: [41.880905],loss2 is: [58.823097], loss is: [50.352] \n",
      "epoch: 0, batch: 141,loss1 is: [61.41007],loss2 is: [71.68257], loss is: [66.54632] \n",
      "epoch: 0, batch: 142,loss1 is: [44.01952],loss2 is: [75.64634], loss is: [59.83293] \n",
      "epoch: 0, batch: 143,loss1 is: [9.334505],loss2 is: [62.45532], loss is: [35.894913] \n",
      "epoch: 0, batch: 144,loss1 is: [55.991383],loss2 is: [68.52259], loss is: [62.25699] \n",
      "epoch: 0, batch: 145,loss1 is: [45.22991],loss2 is: [69.31907], loss is: [57.27449] \n",
      "epoch: 0, batch: 146,loss1 is: [43.279438],loss2 is: [62.5799], loss is: [52.92967] \n",
      "epoch: 0, batch: 147,loss1 is: [70.217995],loss2 is: [81.1115], loss is: [75.66475] \n",
      "epoch: 0, batch: 148,loss1 is: [20.891487],loss2 is: [68.390396], loss is: [44.64094] \n",
      "epoch: 0, batch: 149,loss1 is: [126.14325],loss2 is: [77.558586], loss is: [101.85092] \n",
      "epoch: 0, batch: 150,loss1 is: [14.134794],loss2 is: [70.68741], loss is: [42.411102] \n",
      "epoch: 0, batch: 151,loss1 is: [69.80041],loss2 is: [72.34201], loss is: [71.07121] \n",
      "epoch: 0, batch: 152,loss1 is: [23.84302],loss2 is: [68.588806], loss is: [46.21591] \n",
      "epoch: 0, batch: 153,loss1 is: [0.04011393],loss2 is: [47.03754], loss is: [23.538828] \n",
      "epoch: 0, batch: 154,loss1 is: [46.59122],loss2 is: [67.68457], loss is: [57.137894] \n",
      "epoch: 0, batch: 155,loss1 is: [5.1122007],loss2 is: [65.06528], loss is: [35.088737] \n",
      "epoch: 0, batch: 156,loss1 is: [72.511406],loss2 is: [70.13262], loss is: [71.322014] \n",
      "epoch: 0, batch: 157,loss1 is: [32.365204],loss2 is: [64.752754], loss is: [48.55898] \n",
      "epoch: 0, batch: 158,loss1 is: [0.00071526],loss2 is: [48.39273], loss is: [24.196724] \n",
      "epoch: 0, batch: 159,loss1 is: [36.59016],loss2 is: [67.89259], loss is: [52.24138] \n",
      "epoch: 0, batch: 160,loss1 is: [0.20158291],loss2 is: [64.76454], loss is: [32.483063] \n",
      "epoch: 0, batch: 161,loss1 is: [17.368883],loss2 is: [75.0162], loss is: [46.19254] \n",
      "epoch: 0, batch: 162,loss1 is: [12.116819],loss2 is: [68.94182], loss is: [40.52932] \n",
      "epoch: 0, batch: 163,loss1 is: [60.52476],loss2 is: [78.54339], loss is: [69.53407] \n",
      "epoch: 0, batch: 164,loss1 is: [38.779377],loss2 is: [73.12242], loss is: [55.950897] \n",
      "epoch: 0, batch: 165,loss1 is: [57.80256],loss2 is: [80.72014], loss is: [69.26135] \n",
      "epoch: 0, batch: 166,loss1 is: [5.5283012],loss2 is: [64.96434], loss is: [35.246323] \n",
      "epoch: 0, batch: 167,loss1 is: [52.666187],loss2 is: [69.94369], loss is: [61.30494] \n",
      "epoch: 0, batch: 168,loss1 is: [31.858326],loss2 is: [67.698586], loss is: [49.778458] \n",
      "epoch: 0, batch: 169,loss1 is: [66.08483],loss2 is: [79.96702], loss is: [73.025925] \n",
      "epoch: 0, batch: 170,loss1 is: [63.42],loss2 is: [80.12096], loss is: [71.77048] \n",
      "epoch: 0, batch: 171,loss1 is: [78.55752],loss2 is: [78.600655], loss is: [78.57909] \n",
      "epoch: 0, batch: 172,loss1 is: [38.918854],loss2 is: [66.09919], loss is: [52.50902] \n",
      "epoch: 0, batch: 173,loss1 is: [84.19484],loss2 is: [79.68305], loss is: [81.93895] \n",
      "epoch: 0, batch: 174,loss1 is: [66.9167],loss2 is: [78.38007], loss is: [72.64839] \n",
      "epoch: 0, batch: 175,loss1 is: [30.298233],loss2 is: [72.111885], loss is: [51.20506] \n",
      "epoch: 0, batch: 176,loss1 is: [0.06884336],loss2 is: [60.938435], loss is: [30.50364] \n",
      "epoch: 0, batch: 177,loss1 is: [61.48362],loss2 is: [80.32703], loss is: [70.90532] \n",
      "epoch: 0, batch: 178,loss1 is: [54.891468],loss2 is: [69.44138], loss is: [62.166428] \n",
      "epoch: 0, batch: 179,loss1 is: [12.773573],loss2 is: [63.090607], loss is: [37.93209] \n",
      "epoch: 0, batch: 180,loss1 is: [22.099764],loss2 is: [62.242683], loss is: [42.171223] \n",
      "epoch: 0, batch: 181,loss1 is: [37.111015],loss2 is: [74.77785], loss is: [55.94443] \n",
      "epoch: 0, batch: 182,loss1 is: [66.00538],loss2 is: [74.63949], loss is: [70.32243] \n",
      "epoch: 0, batch: 183,loss1 is: [47.310593],loss2 is: [76.30048], loss is: [61.80554] \n",
      "epoch: 0, batch: 184,loss1 is: [162.0821],loss2 is: [82.22658], loss is: [122.15434] \n",
      "epoch: 0, batch: 185,loss1 is: [0.15637279],loss2 is: [63.462395], loss is: [31.809383] \n",
      "epoch: 0, batch: 186,loss1 is: [60.91228],loss2 is: [75.684784], loss is: [68.29853] \n",
      "epoch: 0, batch: 187,loss1 is: [23.08339],loss2 is: [72.03583], loss is: [47.55961] \n",
      "epoch: 0, batch: 188,loss1 is: [86.662056],loss2 is: [79.822136], loss is: [83.242096] \n",
      "epoch: 0, batch: 189,loss1 is: [13.000668],loss2 is: [63.25382], loss is: [38.127243] \n",
      "epoch: 0, batch: 190,loss1 is: [19.431412],loss2 is: [63.574337], loss is: [41.502876] \n",
      "epoch: 0, batch: 191,loss1 is: [32.32533],loss2 is: [73.03795], loss is: [52.68164] \n",
      "epoch: 0, batch: 192,loss1 is: [14.385075],loss2 is: [63.963947], loss is: [39.17451] \n",
      "epoch: 0, batch: 193,loss1 is: [37.95859],loss2 is: [73.4621], loss is: [55.710342] \n",
      "epoch: 0, batch: 194,loss1 is: [14.135212],loss2 is: [65.858894], loss is: [39.997055] \n",
      "epoch: 0, batch: 195,loss1 is: [43.3501],loss2 is: [73.04587], loss is: [58.197983] \n",
      "epoch: 0, batch: 196,loss1 is: [82.158325],loss2 is: [71.3495], loss is: [76.753914] \n",
      "epoch: 0, batch: 197,loss1 is: [23.444414],loss2 is: [72.63771], loss is: [48.04106] \n",
      "epoch: 0, batch: 198,loss1 is: [45.312943],loss2 is: [59.959038], loss is: [52.63599] \n",
      "epoch: 0, batch: 199,loss1 is: [44.92554],loss2 is: [78.80449], loss is: [61.865013] \n",
      "epoch: 0, batch: 200,loss1 is: [62.621147],loss2 is: [79.12631], loss is: [70.87373] \n",
      "epoch: 0, batch: 201,loss1 is: [0.20346045],loss2 is: [64.109116], loss is: [32.15629] \n",
      "epoch: 0, batch: 202,loss1 is: [148.10378],loss2 is: [82.25431], loss is: [115.17905] \n",
      "epoch: 0, batch: 203,loss1 is: [2.8229952],loss2 is: [64.78806], loss is: [33.80553] \n",
      "epoch: 0, batch: 204,loss1 is: [5.7839155],loss2 is: [68.83984], loss is: [37.31188] \n",
      "epoch: 0, batch: 205,loss1 is: [68.68428],loss2 is: [71.320625], loss is: [70.00246] \n",
      "epoch: 0, batch: 206,loss1 is: [45.090317],loss2 is: [70.68999], loss is: [57.890152] \n",
      "epoch: 0, batch: 207,loss1 is: [65.108],loss2 is: [82.23944], loss is: [73.67372] \n",
      "epoch: 0, batch: 208,loss1 is: [2.7899146],loss2 is: [64.297165], loss is: [33.54354] \n",
      "epoch: 0, batch: 209,loss1 is: [9.902596],loss2 is: [71.5485], loss is: [40.725548] \n",
      "epoch: 0, batch: 210,loss1 is: [75.27423],loss2 is: [73.20687], loss is: [74.240555] \n",
      "epoch: 0, batch: 211,loss1 is: [178.63953],loss2 is: [89.03042], loss is: [133.83498] \n",
      "epoch: 0, batch: 212,loss1 is: [9.286165],loss2 is: [72.26917], loss is: [40.777668] \n",
      "epoch: 0, batch: 213,loss1 is: [31.48806],loss2 is: [66.3974], loss is: [48.94273] \n",
      "epoch: 0, batch: 214,loss1 is: [83.550064],loss2 is: [78.74083], loss is: [81.14545] \n",
      "epoch: 0, batch: 215,loss1 is: [59.197487],loss2 is: [76.351234], loss is: [67.77436] \n",
      "epoch: 0, batch: 216,loss1 is: [80.3937],loss2 is: [83.8777], loss is: [82.1357] \n",
      "epoch: 0, batch: 217,loss1 is: [42.58573],loss2 is: [67.98561], loss is: [55.28567] \n",
      "epoch: 0, batch: 218,loss1 is: [54.97104],loss2 is: [79.84016], loss is: [67.405594] \n",
      "epoch: 0, batch: 219,loss1 is: [29.652803],loss2 is: [77.97943], loss is: [53.816116] \n",
      "epoch: 0, batch: 220,loss1 is: [50.64249],loss2 is: [66.26889], loss is: [58.45569] \n",
      "epoch: 0, batch: 221,loss1 is: [6.182492],loss2 is: [59.807564], loss is: [32.99503] \n",
      "epoch: 0, batch: 222,loss1 is: [41.329266],loss2 is: [59.80633], loss is: [50.5678] \n",
      "epoch: 0, batch: 223,loss1 is: [41.85891],loss2 is: [68.07574], loss is: [54.967323] \n",
      "epoch: 0, batch: 224,loss1 is: [189.49568],loss2 is: [88.639435], loss is: [139.06757] \n",
      "epoch: 0, batch: 225,loss1 is: [20.358355],loss2 is: [69.545166], loss is: [44.95176] \n",
      "epoch: 0, batch: 226,loss1 is: [24.034618],loss2 is: [71.21288], loss is: [47.62375] \n",
      "epoch: 0, batch: 227,loss1 is: [149.31429],loss2 is: [87.196754], loss is: [118.25552] \n",
      "epoch: 0, batch: 228,loss1 is: [60.913445],loss2 is: [78.55764], loss is: [69.73554] \n",
      "epoch: 0, batch: 229,loss1 is: [114.29626],loss2 is: [84.41545], loss is: [99.35585] \n",
      "epoch: 0, batch: 230,loss1 is: [54.21755],loss2 is: [65.36569], loss is: [59.79162] \n",
      "epoch: 0, batch: 231,loss1 is: [37.454456],loss2 is: [66.150024], loss is: [51.80224] \n",
      "epoch: 0, batch: 232,loss1 is: [39.365112],loss2 is: [69.41344], loss is: [54.389275] \n",
      "epoch: 0, batch: 233,loss1 is: [64.26197],loss2 is: [78.901474], loss is: [71.581726] \n",
      "epoch: 0, batch: 234,loss1 is: [71.10399],loss2 is: [79.76876], loss is: [75.43637] \n",
      "epoch: 0, batch: 235,loss1 is: [63.989372],loss2 is: [78.225685], loss is: [71.10753] \n",
      "epoch: 0, batch: 236,loss1 is: [92.24909],loss2 is: [76.94621], loss is: [84.59766] \n",
      "epoch: 0, batch: 237,loss1 is: [76.63083],loss2 is: [81.74191], loss is: [79.18637] \n",
      "epoch: 0, batch: 238,loss1 is: [26.397259],loss2 is: [69.682724], loss is: [48.039993] \n",
      "epoch: 0, batch: 239,loss1 is: [19.523531],loss2 is: [69.33777], loss is: [44.43065] \n",
      "epoch: 0, batch: 240,loss1 is: [24.713278],loss2 is: [68.64337], loss is: [46.678326] \n",
      "epoch: 0, batch: 241,loss1 is: [22.259443],loss2 is: [69.9957], loss is: [46.12757] \n",
      "epoch: 0, batch: 242,loss1 is: [48.809887],loss2 is: [76.602325], loss is: [62.70611] \n",
      "epoch: 0, batch: 243,loss1 is: [79.585495],loss2 is: [78.304565], loss is: [78.94503] \n",
      "epoch: 0, batch: 244,loss1 is: [85.81951],loss2 is: [68.388885], loss is: [77.1042] \n",
      "epoch: 0, batch: 245,loss1 is: [55.89786],loss2 is: [61.680367], loss is: [58.789116] \n",
      "epoch: 0, batch: 246,loss1 is: [2.0356476],loss2 is: [52.46218], loss is: [27.248915] \n",
      "epoch: 0, batch: 247,loss1 is: [0.08672476],loss2 is: [49.236515], loss is: [24.66162] \n",
      "epoch: 0, batch: 248,loss1 is: [66.77088],loss2 is: [76.5644], loss is: [71.66764] \n",
      "epoch: 0, batch: 249,loss1 is: [73.72755],loss2 is: [76.166435], loss is: [74.94699] \n",
      "epoch: 0, batch: 250,loss1 is: [44.410378],loss2 is: [75.52759], loss is: [59.968983] \n",
      "epoch: 0, batch: 251,loss1 is: [52.415043],loss2 is: [81.65932], loss is: [67.03718] \n",
      "epoch: 0, batch: 252,loss1 is: [46.2417],loss2 is: [71.08296], loss is: [58.66233] \n",
      "epoch: 0, batch: 253,loss1 is: [102.790115],loss2 is: [82.03931], loss is: [92.41471] \n",
      "epoch: 0, batch: 254,loss1 is: [61.97533],loss2 is: [76.76731], loss is: [69.37132] \n",
      "epoch: 0, batch: 255,loss1 is: [128.06905],loss2 is: [86.39276], loss is: [107.2309] \n",
      "epoch: 0, batch: 256,loss1 is: [32.473892],loss2 is: [62.822193], loss is: [47.64804] \n",
      "epoch: 0, batch: 257,loss1 is: [101.25726],loss2 is: [74.70653], loss is: [87.981895] \n",
      "epoch: 0, batch: 258,loss1 is: [138.03273],loss2 is: [87.32675], loss is: [112.67974] \n",
      "epoch: 0, batch: 259,loss1 is: [14.865458],loss2 is: [70.686165], loss is: [42.77581] \n",
      "epoch: 0, batch: 260,loss1 is: [52.289783],loss2 is: [74.678955], loss is: [63.484367] \n",
      "epoch: 0, batch: 261,loss1 is: [6.728828],loss2 is: [64.99014], loss is: [35.859486] \n",
      "epoch: 0, batch: 262,loss1 is: [3.091514],loss2 is: [67.7872], loss is: [35.439358] \n",
      "epoch: 0, batch: 263,loss1 is: [24.17922],loss2 is: [68.948586], loss is: [46.563904] \n",
      "epoch: 0, batch: 264,loss1 is: [31.024038],loss2 is: [72.15491], loss is: [51.589474] \n",
      "epoch: 0, batch: 265,loss1 is: [10.524392],loss2 is: [65.242615], loss is: [37.883503] \n",
      "epoch: 0, batch: 266,loss1 is: [38.260696],loss2 is: [62.39864], loss is: [50.329666] \n",
      "epoch: 0, batch: 267,loss1 is: [87.378],loss2 is: [72.73549], loss is: [80.05675] \n",
      "epoch: 0, batch: 268,loss1 is: [75.83571],loss2 is: [70.645035], loss is: [73.24037] \n",
      "epoch: 0, batch: 269,loss1 is: [84.07733],loss2 is: [75.2948], loss is: [79.686066] \n",
      "epoch: 0, batch: 270,loss1 is: [0.08320808],loss2 is: [57.100334], loss is: [28.59177] \n",
      "epoch: 0, batch: 271,loss1 is: [129.76306],loss2 is: [81.44331], loss is: [105.60319] \n",
      "epoch: 0, batch: 272,loss1 is: [27.586042],loss2 is: [60.77391], loss is: [44.179977] \n",
      "epoch: 0, batch: 273,loss1 is: [49.532772],loss2 is: [76.475876], loss is: [63.004326] \n",
      "epoch: 0, batch: 274,loss1 is: [0.10925531],loss2 is: [42.88454], loss is: [21.496899] \n",
      "epoch: 0, batch: 275,loss1 is: [75.90047],loss2 is: [80.68054], loss is: [78.290504] \n",
      "epoch: 0, batch: 276,loss1 is: [23.607433],loss2 is: [73.20006], loss is: [48.403748] \n",
      "epoch: 0, batch: 277,loss1 is: [0.46044588],loss2 is: [66.456276], loss is: [33.458363] \n",
      "epoch: 0, batch: 278,loss1 is: [55.40937],loss2 is: [79.97453], loss is: [67.691956] \n",
      "epoch: 0, batch: 279,loss1 is: [7.422209],loss2 is: [68.5297], loss is: [37.975956] \n",
      "epoch: 0, batch: 280,loss1 is: [75.1352],loss2 is: [79.97714], loss is: [77.55617] \n",
      "epoch: 0, batch: 281,loss1 is: [55.555283],loss2 is: [75.580345], loss is: [65.56781] \n",
      "epoch: 0, batch: 282,loss1 is: [57.204784],loss2 is: [79.01201], loss is: [68.1084] \n",
      "epoch: 0, batch: 283,loss1 is: [18.566996],loss2 is: [72.38545], loss is: [45.476223] \n",
      "epoch: 0, batch: 284,loss1 is: [59.54188],loss2 is: [75.126205], loss is: [67.334045] \n",
      "epoch: 0, batch: 285,loss1 is: [0.18763542],loss2 is: [62.308723], loss is: [31.24818] \n",
      "epoch: 0, batch: 286,loss1 is: [80.42252],loss2 is: [72.602295], loss is: [76.512405] \n",
      "epoch: 0, batch: 287,loss1 is: [123.42647],loss2 is: [81.29382], loss is: [102.360146] \n",
      "epoch: 0, batch: 288,loss1 is: [5.3197145],loss2 is: [70.64363], loss is: [37.981674] \n",
      "epoch: 0, batch: 289,loss1 is: [66.34995],loss2 is: [79.70848], loss is: [73.02922] \n",
      "epoch: 0, batch: 290,loss1 is: [78.5628],loss2 is: [76.97748], loss is: [77.77014] \n",
      "epoch: 0, batch: 291,loss1 is: [29.539644],loss2 is: [71.68192], loss is: [50.610783] \n",
      "epoch: 0, batch: 292,loss1 is: [61.459095],loss2 is: [76.14093], loss is: [68.80001] \n",
      "epoch: 0, batch: 293,loss1 is: [0.10475516],loss2 is: [60.490295], loss is: [30.297525] \n",
      "epoch: 0, batch: 294,loss1 is: [-0.02282858],loss2 is: [50.629887], loss is: [25.30353] \n",
      "epoch: 0, batch: 295,loss1 is: [13.762236],loss2 is: [70.37044], loss is: [42.066338] \n",
      "epoch: 0, batch: 296,loss1 is: [49.833508],loss2 is: [82.06729], loss is: [65.9504] \n",
      "epoch: 0, batch: 297,loss1 is: [11.027366],loss2 is: [66.02998], loss is: [38.528675] \n",
      "epoch: 0, batch: 298,loss1 is: [95.75015],loss2 is: [79.45866], loss is: [87.6044] \n",
      "epoch: 0, batch: 299,loss1 is: [74.31734],loss2 is: [80.63767], loss is: [77.47751] \n",
      "epoch: 0, batch: 300,loss1 is: [75.020195],loss2 is: [80.72942], loss is: [77.87481] \n",
      "epoch: 0, batch: 301,loss1 is: [44.917522],loss2 is: [78.10564], loss is: [61.51158] \n",
      "epoch: 0, batch: 302,loss1 is: [34.42204],loss2 is: [73.4778], loss is: [53.94992] \n",
      "epoch: 0, batch: 303,loss1 is: [70.423065],loss2 is: [77.359116], loss is: [73.89109] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MIRNet_v2(n_feat=64)\n",
    "#paddle.summary(model, (1, 3, 600, 600))\n",
    "#model = UNet()\n",
    "# param_dict = paddle.load('MIRNetV2.pdparams')\n",
    "# model.load_dict(param_dict)\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "paddle.seed(1234)\n",
    "model.train()\n",
    "\n",
    "train_dataset=MyDateset()\n",
    "\n",
    "# 需要接续之前的模型重复训练可以取消注释\n",
    "# param_dict = paddle.load('./MIRnetV2_model_13.pdparams')\n",
    "# model.load_dict(param_dict)\n",
    "\n",
    "train_dataloader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    drop_last=False)\n",
    "\n",
    "losspsnr = PSNRLoss()\n",
    "lossfn = SSIMLoss(window_size=3,data_range=1)\n",
    "\n",
    "max_epoch=101\n",
    "scheduler = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=0.0005, T_max=max_epoch,eta_min=1e-6)\n",
    "opt = paddle.optimizer.Adam(learning_rate=scheduler, parameters=model.parameters(),weight_decay=1e-8)  \n",
    "now_step=0\n",
    "loss1_list = []\n",
    "loss2_list = []\n",
    "import time\n",
    "print(len(train_dataloader))\n",
    "for epoch in range(max_epoch):\n",
    "    if epoch >= 0:\n",
    "        loss1_list_tmp = []\n",
    "        loss2_list_tmp = []\n",
    "        for step, data in enumerate(train_dataloader):\n",
    "            now_step+=1\n",
    "            img, label = data\n",
    "            pre = model(img)\n",
    "            loss1 = lossfn(pre,label).mean()\n",
    "            loss2 = losspsnr(pre,label).mean()\n",
    "            # Score=0.5∗ 100 PSNR​+0.5∗MSSSIM\n",
    "            loss = (500*loss1+loss2)/2\n",
    "            loss1_list_tmp.append((loss1.numpy()[0]))\n",
    "            loss2_list_tmp.append((loss2.numpy()[0]))\n",
    "            loss.backward()     \n",
    "            opt.step() \n",
    "            opt.clear_gradients()\n",
    "            if now_step%1==0:\n",
    "                print(\"epoch: {}, batch: {},loss1 is: {},loss2 is: {}, loss is: {} \".format(epoch, step, loss1.mean().numpy()*500,loss2.mean().numpy(), loss.mean().numpy()))\n",
    "            # if now_step%1000==0:\n",
    "            #     paddle.save(model.state_dict(), f\"NAFnet_model_{epoch}_{now_step}.pdparams\")\n",
    "            #     time.sleep(50)\n",
    "        loss1_list.append(sum(loss1_list_tmp)/len(loss1_list_tmp))\n",
    "        loss2_list.append(sum(loss2_list_tmp)/len(loss2_list_tmp))\n",
    "        with open(\"losss_MIRV2.txt\",\"w\") as f:\n",
    "            f.write(str(loss1_list)+\"\\n\")\n",
    "            f.write(str(loss2_list)+\"\\n\")\n",
    "        paddle.save(model.state_dict(), f\"MIRnetV2_model_{epoch}.pdparams\")\n",
    "        print(loss1_list)\n",
    "from matplotlib import pyplot as plt\n",
    "print(loss1_list)\n",
    "print(loss2_list)\n",
    "plt.plot(loss1_list,label='loss 1')\n",
    "plt.plot(loss2_list,label='loss 2')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T23:37:56.208705Z",
     "iopub.status.busy": "2022-06-29T23:37:56.207557Z",
     "iopub.status.idle": "2022-06-29T23:38:56.240490Z",
     "shell.execute_reply": "2022-06-29T23:38:56.239328Z",
     "shell.execute_reply.started": "2022-06-29T23:37:56.208665Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0630 07:37:57.758509  8064 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0630 07:37:57.763079  8064 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "! python predict.py data/data154549/train_data_01/deblur_testA/blur_image results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
